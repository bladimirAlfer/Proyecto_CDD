# Sistema de PredicciÃ³n Espacio-Temporal de Delitos en Lima Metropolitana

---

## AplicaciÃ³n en LÃ­nea

**La aplicaciÃ³n web estÃ¡ desplegada y disponible en:**

ğŸ”— **[https://bladimiralfer-proyecto-cdd-app-ii1kxc.streamlit.app/](https://bladimiralfer-proyecto-cdd-app-ii1kxc.streamlit.app/)**

La aplicaciÃ³n permite visualizar predicciones de delitos, explorar datos histÃ³ricos, generar reportes y analizar tendencias por distrito mediante una interfaz interactiva con mapas 3D y visualizaciones avanzadas.

---

## Tabla de Contenidos

1. [DescripciÃ³n General](#descripciÃ³n-general)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [Componentes del Modelo](#componentes-del-modelo)
4. [Decisiones de DiseÃ±o](#decisiones-de-diseÃ±o)
5. [InstalaciÃ³n y ConfiguraciÃ³n](#instalaciÃ³n-y-configuraciÃ³n)
6. [Uso del Sistema](#uso-del-sistema)
7. [AplicaciÃ³n Web (Streamlit)](#aplicaciÃ³n-web-streamlit)
8. [API y Funcionalidades](#api-y-funcionalidades)
9. [Deployment](#deployment)
10. [MÃ©tricas y EvaluaciÃ³n](#mÃ©tricas-y-evaluaciÃ³n)
11. [Estructura del Proyecto](#estructura-del-proyecto)
12. [Referencias](#referencias)
13. [SoluciÃ³n de Problemas](#soluciÃ³n-de-problemas)

---

## DescripciÃ³n General

Este proyecto implementa un **sistema integrado de predicciÃ³n espacio-temporal de delitos** para Lima Metropolitana, utilizando datos anuales de denuncias policiales desde 2016 hasta 2023. El sistema proporciona predicciones a nivel distrital mediante dos enfoques complementarios:

1. **Modelo Integrado de Grafos (GCN + LSTM + Attention)**: Arquitectura de deep learning que combina redes convolucionales de grafos, redes neuronales recurrentes y mecanismos de atenciÃ³n para capturar patrones espacio-temporales complejos.

2. **Modelo Baseline (Random Forest / XGBoost)**: Enfoque basado en Ã¡rboles de decisiÃ³n con features temporales y espaciales para comparaciÃ³n y validaciÃ³n.

### Objetivos

- Predecir tasas de delitos por distrito para aÃ±os futuros (ej: 2024)
- Identificar patrones espacio-temporales en la criminalidad urbana
- Proporcionar una interfaz interactiva para visualizaciÃ³n y anÃ¡lisis
- Facilitar la toma de decisiones para asignaciÃ³n de recursos policiales

### InspiraciÃ³n AcadÃ©mica

Este proyecto estÃ¡ inspirado y adaptado del siguiente trabajo de investigaciÃ³n:

> **"An Integrated Graph Model for Spatialâ€“Temporal Urban Crime Prediction Based on Attention Mechanism"** (Hou et al., 2022)

El modelo integrado implementa una arquitectura similar, adaptada a las caracterÃ­sticas especÃ­ficas de los datos de Lima Metropolitana.

---

## Arquitectura del Sistema

### Diagrama de Arquitectura General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CAPA DE DATOS                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ final2016.csvâ”‚  â”‚ final2017.csvâ”‚  â”‚  final20XX   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚         â”‚                  â”‚                  â”‚                 â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                            â”‚                                    â”‚
â”‚                            â–¼                                    â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚              â”‚  Pipeline de Procesamiento                       â”‚
â”‚              â”‚  - NormalizaciÃ³n de esquema                      â”‚
â”‚              â”‚  - CÃ¡lculo de centroides                         â”‚
â”‚              â”‚  - ConstrucciÃ³n de grafo (kNN)                   â”‚
â”‚              â”‚  - AgregaciÃ³n temporal (aÃ±o Ã— distrito)          â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                         â”‚
                â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Modelo Integrado         â”‚  â”‚  Modelo Baseline           â”‚
â”‚  (GCN + LSTM + Attention) â”‚  â”‚  (RF / XGBoost)            â”‚
â”‚                           â”‚  â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ResBlock MLP       â”‚   â”‚  â”‚  â”‚ Feature Engineering  â”‚  â”‚
â”‚  â”‚   (Embedding)      â”‚   â”‚  â”‚  â”‚ - Lags temporales    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â”‚ - Rolling stats      â”‚  â”‚
â”‚           â”‚               â”‚  â”‚  â”‚ - Shares categÃ³ricosâ”‚   â”‚
â”‚           â–¼               â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚             â”‚              â”‚
â”‚  â”‚ GCN Layer          â”‚   â”‚  â”‚             â–¼              â”‚
â”‚  â”‚   (Relaciones      â”‚   â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    espaciales)     â”‚   â”‚  â”‚  â”‚ RF/XGB Regressor     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚               â”‚  â”‚                            â”‚
â”‚           â–¼               â”‚  â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚                            â”‚
â”‚  â”‚ BiLSTM             â”‚   â”‚  â”‚                            â”‚
â”‚  â”‚   (Dependencias    â”‚   â”‚  â”‚                            â”‚
â”‚  â”‚    temporales)     â”‚   â”‚  â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚                            â”‚
â”‚           â”‚               â”‚  â”‚                            â”‚
â”‚           â–¼               â”‚  â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚                            â”‚
â”‚  â”‚ Temporal Attention â”‚   â”‚  â”‚                            â”‚
â”‚  â”‚   (PonderaciÃ³n)    â”‚   â”‚  â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚                            â”‚
â”‚           â”‚               â”‚  â”‚                            â”‚
â”‚           â–¼               â”‚  â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚                            â”‚
â”‚  â”‚ Output Projection  â”‚   â”‚  â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Predicciones         â”‚
        â”‚   (Tasa por distrito)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚
        â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AplicaciÃ³n      â”‚    â”‚  Archivos de Salida â”‚
â”‚  Streamlit       â”‚    â”‚  - integrated_model â”‚
â”‚  (VisualizaciÃ³n) â”‚    â”‚  - report.json      â”‚
â”‚                  â”‚    â”‚  - metrics.json     â”‚
â”‚  - Mapa 3D       â”‚    â”‚  - predictions.csv  â”‚
â”‚  - KPIs          â”‚    â”‚                     â”‚
â”‚  - GrÃ¡ficos      â”‚    â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos del Modelo Integrado

```
Entrada: Serie temporal por distrito
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ T-2  â”‚  T-1  â”‚  T    â”‚  (seq_len=3)    â”‚
â”‚ [N]  â”‚  [N]  â”‚  [N]  â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
         â”‚                               â”‚
         â–¼                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ ResBlock MLP        â”‚                  â”‚
â”‚ (B, S, N, 1) â†’      â”‚                  â”‚
â”‚ (B, S, N, hidden)   â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
          â”‚                              â”‚
          â–¼                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ GCN Layer           â”‚                  â”‚
â”‚ Propaga informaciÃ³n â”‚                  â”‚
â”‚ entre distritos     â”‚                  â”‚
â”‚ vecinos (kNN)       â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
          â”‚                              â”‚
          â–¼                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ BiLSTM              â”‚                  â”‚
â”‚ Modela dependencias â”‚                  â”‚
â”‚ temporales          â”‚                  â”‚
â”‚ (B, N, S, F)        â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
          â”‚                              â”‚
          â–¼                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ Temporal Attention  â”‚                  â”‚
â”‚ PonderaciÃ³n de      â”‚                  â”‚
â”‚ pasos temporales    â”‚                  â”‚
â”‚ (B, N, F)           â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
          â”‚                              â”‚
          â–¼                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ Output Projection   â”‚                  â”‚
â”‚ (B, N, F) â†’ (B, N)  â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
          â”‚                              â”‚
          â–¼                              â”‚
   PredicciÃ³n T+1
      [N] (distritos)
```

---

## Componentes del Modelo

### 1. Bloque MLP Residual (ResBlockMLP)

**PropÃ³sito**: Transforma los valores de entrada (conteos de delitos) en representaciones latentes de mayor dimensionalidad, permitiendo al modelo capturar relaciones no lineales.

**Arquitectura**:
- Dos capas lineales con activaciÃ³n ReLU
- ConexiÃ³n residual para facilitar el entrenamiento profundo
- ProyecciÃ³n de dimensionalidad si `in_ch != hidden`

**Dimensiones**: `(B, S, N, 1) â†’ (B, S, N, hidden_dim)`

**JustificaciÃ³n**: Las conexiones residuales mejoran el flujo de gradientes y permiten entrenar arquitecturas mÃ¡s profundas. Este bloque procesa cada distrito y cada paso temporal de forma independiente antes de la propagaciÃ³n espacial.

### 2. Red de ConvoluciÃ³n de Grafos (SimpleGCNLayer)

**PropÃ³sito**: Captura relaciones espaciales entre distritos mediante la propagaciÃ³n de informaciÃ³n a travÃ©s de la matriz de adyacencia del grafo.

**ConstrucciÃ³n del Grafo**:
- **Matriz de Adyacencia**: Basada en k-vecinos mÃ¡s cercanos (kNN) usando distancia euclidiana entre centroides de distritos
- **NormalizaciÃ³n**: Por grado (row-normalized) para estabilidad numÃ©rica
- **SimetrÃ­a**: La matriz es simÃ©trica (grafos no dirigidos)

**Dimensiones**: `(B, S, N, hidden) â†’ (B, S, N, hidden)`

**Trade-offs**:
- **Ventaja**: Captura influencia espacial entre distritos vecinos sin necesidad de lÃ­mites administrativos exactos
- **LimitaciÃ³n**: Depende de la calidad de los centroides calculados. Distritos con formas irregulares pueden tener centroides no representativos.

**Alternativas consideradas**:
- Usar lÃ­mites administrativos reales (requiere datos GIS adicionales)
- Grafos dirigidos basados en flujos poblacionales (complejidad adicional)
- Multiple scales (multi-scale GCN) para capturar relaciones a diferentes distancias

### 3. LSTM Bidireccional

**PropÃ³sito**: Modela dependencias temporales secuenciales, capturando patrones de corto y largo plazo en las series de tiempo.

**ConfiguraciÃ³n**:
- Bidireccional para capturar contexto hacia adelante y atrÃ¡s
- DimensiÃ³n oculta: `hidden_dim // 2` en cada direcciÃ³n
- `batch_first=True` para compatibilidad con PyTorch

**Dimensiones**: `(B*N, S, hidden) â†’ (B*N, S, hidden)`

**JustificaciÃ³n**: La bidireccionalidad permite al modelo considerar tanto el pasado como el "futuro contextual" de cada paso temporal, mejorando la comprensiÃ³n de tendencias. Se procesa cada distrito de forma independiente en la dimensiÃ³n temporal.

### 4. Mecanismo de AtenciÃ³n Temporal (TemporalAttention)

**PropÃ³sito**: Pondera dinÃ¡micamente la importancia de diferentes pasos temporales, permitiendo al modelo enfocarse en perÃ­odos mÃ¡s relevantes para la predicciÃ³n.

**ImplementaciÃ³n**:
- AtenciÃ³n basada en Query-Key-Value (similar a Transformers)
- Softmax sobre la dimensiÃ³n temporal
- AgregaciÃ³n mediante suma ponderada

**Dimensiones**: `(B, S, N, hidden) â†’ (B, N, hidden)`

**Ventajas**:
- Interpretabilidad: Los pesos de atenciÃ³n pueden indicar quÃ© perÃ­odos histÃ³ricos son mÃ¡s relevantes
- Adaptabilidad: Se ajusta automÃ¡ticamente segÃºn los patrones de cada distrito

**Trade-offs**:
- **Ventaja**: Mayor flexibilidad que promedios simples o ventanas fijas
- **Costo**: Requiere parÃ¡metros adicionales y cÃ³mputo extra

### 5. ProyecciÃ³n Final (Output Projection)

**PropÃ³sito**: Mapea las representaciones latentes a predicciones numÃ©ricas (tasas de delitos).

**Arquitectura**:
- Dos capas lineales con activaciÃ³n ReLU intermedia
- ReducciÃ³n gradual: `hidden_dim â†’ hidden_dim//2 â†’ 1`
- Salida escalar por distrito

**Dimensiones**: `(B, N, hidden) â†’ (B, N, 1) â†’ (B, N)`

---

## Decisiones de DiseÃ±o

### DivisiÃ³n Temporal de Datos

**DecisiÃ³n**: Split temporal 70% entrenamiento / 30% prueba (no aleatorio por aÃ±o)

**JustificaciÃ³n**:
- Preserva la naturaleza temporal de los datos
- Evita data leakage (informaciÃ³n futura no disponible en entrenamiento)
- Simula escenario real: predecir aÃ±os futuros basado en historia pasada

**Trade-offs**:
- **Ventaja**: MÃ¡s realista para producciÃ³n
- **LimitaciÃ³n**: Menos datos de prueba (solo Ãºltimos aÃ±os)
- **Alternativa rechazada**: K-fold temporal (menos intuitivo para evaluaciÃ³n de aÃ±os especÃ­ficos)

### ConstrucciÃ³n de la Matriz de Adyacencia

**DecisiÃ³n**: k-Nearest Neighbors basado en distancia euclidiana entre centroides

**JustificaciÃ³n**:
- Simple y eficiente de calcular
- No requiere datos GIS adicionales (lÃ­mites administrativos)
- Captura proximidad geogrÃ¡fica como proxy de influencia espacial

**Trade-offs**:
- **Ventaja**: Funciona con datos mÃ­nimos (solo coordenadas)
- **LimitaciÃ³n**: Puede conectar distritos no adyacentes administrativamente
- **Alternativa considerada**: Usar lÃ­mites administrativos reales (requiere datos adicionales, implementaciÃ³n futura)

**Valor de k**: Por defecto `gcn_k=4`, configurable segÃºn anÃ¡lisis de conectividad espacial.

### NormalizaciÃ³n de Datos

**DecisiÃ³n**: StandardScaler ajustado solo con datos de entrenamiento

**JustificaciÃ³n**:
- Previene data leakage (scaler no "ve" datos de prueba)
- Establece rangos consistentes para el modelo
- Facilita convergencia del entrenamiento

**Trade-offs**:
- **Ventaja**: PrÃ¡ctica estÃ¡ndar en ML, previene overfitting
- **ConsideraciÃ³n**: Requiere guardar parÃ¡metros del scaler para inferencia

### Ventana Temporal (seq_len)

**DecisiÃ³n**: Por defecto `seq_len=3` (usa 3 aÃ±os de historia para predecir el siguiente)

**JustificaciÃ³n**:
- Balance entre contexto histÃ³rico y capacidad de generalizaciÃ³n
- Considera que con 8 aÃ±os de datos (2016-2023), usar mÃ¡s de 3 reduce significativamente ejemplos de entrenamiento

**Trade-offs**:
- **Ventaja**: Suficiente contexto para capturar tendencias
- **LimitaciÃ³n**: Puede perder patrones de muy largo plazo
- **Alternativa**: `seq_len=5` (probablemente mejor si hay mÃ¡s datos histÃ³ricos)

### SelecciÃ³n del Dispositivo (CPU vs GPU)

**DecisiÃ³n**: DetecciÃ³n automÃ¡tica con fallback a CPU

**JustificaciÃ³n**:
- Accesibilidad: Funciona en mÃ¡quinas sin GPU
- Rendimiento: Aprovecha GPU si estÃ¡ disponible
- Flexibilidad: Permite forzar CPU para debugging

**Trade-offs**:
- **GPU**: Entrenamiento 5-10x mÃ¡s rÃ¡pido, pero requiere hardware adicional
- **CPU**: MÃ¡s lento pero universalmente disponible

### Early Stopping

**DecisiÃ³n**: ValidaciÃ³n basada en RMSE con paciencia configurable

**JustificaciÃ³n**:
- Previene overfitting
- Ahorra tiempo de cÃ³mputo
- Encuentra el mejor modelo sin necesidad de entrenar todas las Ã©pocas

**Trade-offs**:
- **Ventaja**: Automatiza el proceso de selecciÃ³n de modelo
- **ConsideraciÃ³n**: Puede detenerse temprano si la mÃ©trica fluctÃºa (requiere ajuste de paciencia)

---

## InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos

- **Python**: 3.8 o superior
- **CUDA** (opcional): Para aceleraciÃ³n con GPU
- **Memoria**: MÃ­nimo 8GB RAM recomendado
- **Espacio en disco**: ~500MB para datos y modelos

### InstalaciÃ³n Paso a Paso

#### 1. Clonar el Repositorio

```bash
git clone https://github.com/bladimirAlfer/Proyecto_CDD.git
cd Proyecto_CDD
```

#### 2. Crear Entorno Virtual (Recomendado)

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python -m venv venv
source venv/bin/activate
```

#### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

**Nota sobre PyTorch**: Si tienes GPU disponible y quieres usar CUDA, instala PyTorch con soporte CUDA desde [pytorch.org](https://pytorch.org/get-started/locally/) antes de instalar las otras dependencias. Por ejemplo:

```bash
# Ejemplo para CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
```

#### 4. Verificar InstalaciÃ³n

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA disponible: {torch.cuda.is_available()}')"
```

### Estructura de Datos Requerida

El pipeline espera archivos CSV en la carpeta `data/` con el siguiente formato:

- Archivos: `final2016.csv`, `final2017.csv`, ..., `final2023.csv`
- Columnas requeridas:
  - `anio`: AÃ±o del incidente (numÃ©rico, ej: 2016)
  - `X`: Coordenada X / Longitud (numÃ©rico)
  - `Y`: Coordenada Y / Latitud (numÃ©rico)
  - `distrito`: Nombre del distrito (texto)

**Ejemplo de datos**:

```csv
anio,X,Y,distrito
2016,-77.042793,-12.046374,LIMA
2016,-77.028240,-12.087502,MIRAFLORES
...
```

### ConfiguraciÃ³n del Pipeline

Los parÃ¡metros principales se definen en `main_version_preliminar.py` mediante la clase `CFG`:

```python
@dataclass
class CFG:
    data_glob: str = "./data/final*.csv"  # PatrÃ³n de archivos
    seq_len: int = 3                       # Longitud de ventana temporal
    batch_size: int = 64                   # TamaÃ±o de batch
    epochs: int = 40                       # NÃºmero de Ã©pocas
    lr: float = 1e-3                       # Learning rate
    hidden_dim: int = 64                   # DimensiÃ³n oculta
    gcn_k: int = 4                         # NÃºmero de vecinos para GCN
    device: str = "cuda" if torch.cuda.is_available() else "cpu"
    outdir: str = "ig_outputs"             # Directorio de salida
```

---

## Uso del Sistema

### Entrenamiento del Modelo Integrado

#### EjecuciÃ³n BÃ¡sica

```bash
python main_version_preliminar.py
```

Este comando ejecuta el pipeline completo:

1. **Carga de datos**: Lee y concatena todos los CSV que coinciden con `data/final*.csv`
2. **NormalizaciÃ³n**: Estandariza tipos y formatos, calcula centroides por distrito
3. **ConstrucciÃ³n del grafo**: Crea matriz de adyacencia basada en k-vecinos mÃ¡s cercanos (kNN)
4. **AgregaciÃ³n temporal**: Convierte datos a serie temporal (aÃ±os Ã— distritos)
5. **DivisiÃ³n temporal**: Split 70% entrenamiento / 30% prueba
6. **Escalado**: NormalizaciÃ³n usando solo datos de entrenamiento
7. **Entrenamiento**: Entrena el modelo integrado con early stopping basado en RMSE de validaciÃ³n
8. **EvaluaciÃ³n**: Calcula mÃ©tricas (MAE, RMSE, MAPE) en conjunto de prueba
9. **Guardado**: Guarda el mejor modelo y genera reporte JSON

#### Salidas Generadas

El pipeline genera los siguientes archivos en `ig_outputs/`:

- `integrated_model.pt`: Modelo entrenado con mejor rendimiento en validaciÃ³n
  - Contiene: estado del modelo, scaler (mean, scale), nombres de distritos, matriz de adyacencia, configuraciÃ³n
- `report.json`: Reporte con mÃ©tricas de evaluaciÃ³n (MAE, RMSE, MAPE)

**Ejemplo de report.json**:

```json
{
  "test_mae": 234.5,
  "test_rmse": 312.8,
  "test_mape": 42.3,
  "val_mae": 198.2,
  "val_rmse": 287.1,
  "val_mape": 38.7
}
```

### Entrenamiento del Modelo Baseline

El modelo baseline (Random Forest / XGBoost) se entrena mediante `main.py`:

```bash
python main.py --csv data/ALL_DATA.csv
```

Este modelo utiliza un enfoque diferente basado en features temporales y espaciales. Ver documentaciÃ³n en `main.py` para opciones adicionales.

### BÃºsqueda de HiperparÃ¡metros

Para optimizar los hiperparÃ¡metros del modelo integrado, utiliza `grid_search.py`:

```bash
python grid_search.py
```

Este script prueba mÃºltiples combinaciones de hiperparÃ¡metros y guarda la mejor configuraciÃ³n encontrada. Consulta el archivo para ver los rangos de bÃºsqueda configurados.

### Ejemplos de Uso Avanzado

#### Modificar la Ventana Temporal

Edita `main_version_preliminar.py`:

```python
cfg.seq_len = 5  # Usa 5 aÃ±os de historia en lugar de 3
```

#### Cambiar el NÃºmero de Vecinos en el Grafo

```python
cfg.gcn_k = 6  # Conecta con 6 vecinos mÃ¡s cercanos
```

#### Forzar Uso de CPU

```python
cfg.device = "cpu"
```

#### Ajustar ParÃ¡metros de Entrenamiento

```python
cfg.batch_size = 32      # Batch mÃ¡s pequeÃ±o para memoria limitada
cfg.epochs = 60          # MÃ¡s Ã©pocas para entrenamiento mÃ¡s largo
cfg.lr = 5e-4            # Learning rate mÃ¡s conservador
cfg.hidden_dim = 128     # DimensiÃ³n oculta mayor
```

---

## AplicaciÃ³n Web (Streamlit)

### DescripciÃ³n

La aplicaciÃ³n web proporciona una interfaz interactiva para visualizar predicciones, explorar datos histÃ³ricos y generar reportes. EstÃ¡ implementada con Streamlit y utiliza visualizaciones 3D mediante PyDeck.

### Acceder a la AplicaciÃ³n

**OpciÃ³n 1: VersiÃ³n Desplegada (Recomendado)**

La aplicaciÃ³n estÃ¡ disponible en lÃ­nea sin necesidad de instalaciÃ³n:

ğŸ”— **[https://bladimiralfer-proyecto-cdd-app-ii1kxc.streamlit.app/](https://bladimiralfer-proyecto-cdd-app-ii1kxc.streamlit.app/)**

**OpciÃ³n 2: EjecuciÃ³n Local**

Para ejecutar la aplicaciÃ³n localmente en tu mÃ¡quina:

```bash
streamlit run app.py
```

La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en tu navegador (por defecto en `http://localhost:8501`).

### Requisitos Previos

- El modelo debe estar entrenado y guardado en `ig_outputs/integrated_model.pt`
- Los archivos CSV de datos histÃ³ricos deben estar en `data/`

### Funcionalidades Principales

#### 1. Panel de Control (Sidebar)

- **Filtros de AnÃ¡lisis**:
  - Rango de incidentes permitido: Filtra distritos por rango de predicciones
  - Filtro de distritos especÃ­ficos: Selecciona uno o mÃ¡s distritos para anÃ¡lisis focalizado
  - InclinaciÃ³n del mapa 3D: Ajusta el Ã¡ngulo de visualizaciÃ³n

#### 2. KPIs TÃ¡cticos

La aplicaciÃ³n muestra cuatro mÃ©tricas clave:

- **AÃ±o de ProyecciÃ³n**: AÃ±o futuro para el cual se generan las predicciones
- **ProyecciÃ³n Total**: Suma total de delitos estimados (con delta porcentual vs aÃ±o anterior)
- **Zona de Mayor Riesgo**: Distrito con mayor cantidad de delitos proyectados
- **Incidentes en Zona de Mayor Riesgo**: Volumen especÃ­fico de delitos proyectados

Los KPIs se actualizan dinÃ¡micamente segÃºn los filtros aplicados (global o selecciÃ³n especÃ­fica).

#### 3. PestaÃ±a: Mapa TÃ¡ctico

VisualizaciÃ³n interactiva 3D de las predicciones:

- **Columnas 3D**: Altura proporcional a la cantidad de delitos proyectados
- **Colores dinÃ¡micos**: Escala de colores segÃºn nivel de riesgo
  - Gris oscuro: Bajo riesgo
  - Amarillo/Naranja: Medio riesgo
  - Rojo: Alto riesgo (CrÃ­tico)
- **Tooltips informativos**: Al hacer hover sobre una columna, se muestra:
  - Nombre del distrito
  - ProyecciÃ³n de delitos
  - Nivel de riesgo
  - Valor del aÃ±o anterior
  - Tendencia (Sube/Baja)

**Leyenda**:
- Bajo: Incidentes < 500
- Medio: Incidentes entre 500-1500
- CrÃ­tico: Incidentes > 1500

#### 4. PestaÃ±a: Comparativa

GrÃ¡fico de barras comparando:

- Valores reales del aÃ±o anterior
- Predicciones para el aÃ±o futuro

Muestra los top 20 distritos (o todos si hay filtro de selecciÃ³n activo). Permite identificar diferencias entre realidad y proyecciÃ³n para validar el modelo.

#### 5. PestaÃ±a: Datos

Tabla interactiva con todos los datos operativos:

- Distrito
- Nivel de Riesgo
- Real Anterior (aÃ±o pasado)
- ProyecciÃ³n (aÃ±o futuro)
- Diferencia (absoluta)
- Tendencia (Sube/Baja)

**Funcionalidades**:
- Ordenamiento por cualquier columna
- Filtrado mediante selecciÃ³n de distritos en sidebar
- Gradiente de color en columna "ProyecciÃ³n" (rojo = mayor riesgo)
- BotÃ³n de descarga: Exporta los datos filtrados como CSV

### Arquitectura de la AplicaciÃ³n

```
app.py
â”œâ”€â”€ Carga del Sistema (@st.cache_resource)
â”‚   â”œâ”€â”€ Carga modelo entrenado (integrated_model.pt)
â”‚   â”œâ”€â”€ Carga nombres de distritos y configuraciÃ³n
â”‚   â”œâ”€â”€ Carga scaler (mean, scale)
â”‚   â””â”€â”€ Carga matriz de adyacencia
â”‚
â”œâ”€â”€ Carga de Datos HistÃ³ricos (@st.cache_data)
â”‚   â”œâ”€â”€ Lee todos los CSV (final*.csv)
â”‚   â”œâ”€â”€ Calcula centroides por distrito
â”‚   â””â”€â”€ Genera tabla pivot (aÃ±o Ã— distrito)
â”‚
â”œâ”€â”€ Inferencia
â”‚   â”œâ”€â”€ Prepara ventana temporal (Ãºltimos seq_len aÃ±os)
â”‚   â”œâ”€â”€ Normaliza datos
â”‚   â”œâ”€â”€ Ejecuta modelo (forward pass)
â”‚   â””â”€â”€ Desnormaliza predicciones
â”‚
â””â”€â”€ VisualizaciÃ³n
    â”œâ”€â”€ KPIs (mÃ©tricas principales)
    â”œâ”€â”€ Mapa 3D (PyDeck)
    â”œâ”€â”€ GrÃ¡fico comparativo (Altair)
    â””â”€â”€ Tabla de datos (Pandas DataFrame)
```

### Optimizaciones de Rendimiento

- **CachÃ© de recursos**: El modelo se carga una vez con `@st.cache_resource`
- **CachÃ© de datos**: Los datos histÃ³ricos se cargan una vez con `@st.cache_data`
- **CÃ¡lculos eficientes**: Las predicciones se calculan una vez al inicio y se reutilizan

### PersonalizaciÃ³n de la Interfaz

Los estilos CSS estÃ¡n definidos en la secciÃ³n de configuraciÃ³n de `app.py`. Puedes modificar:

- Colores de mÃ©tricas
- Estilos de leyenda
- Tema del mapa (dark/light)

---

## API y Funcionalidades

### Funciones Principales del Pipeline

#### `load_and_concatenate(glob_pattern: str) -> pd.DataFrame`

Carga y concatena mÃºltiples archivos CSV.

**ParÃ¡metros**:
- `glob_pattern`: PatrÃ³n de bÃºsqueda de archivos (ej: `"./data/final*.csv"`)

**Retorna**: DataFrame con todos los datos concatenados

**Lanza**: `FileNotFoundError` si no se encuentran archivos

#### `normalize_schema(df: pd.DataFrame) -> pd.DataFrame`

Normaliza y valida el esquema de datos.

**ParÃ¡metros**:
- `df`: DataFrame con datos crudos

**Retorna**: DataFrame normalizado con tipos correctos

**Lanza**: `ValueError` si faltan columnas requeridas

#### `build_district_centroids(df: pd.DataFrame) -> pd.DataFrame`

Calcula centroides geogrÃ¡ficos por distrito.

**ParÃ¡metros**:
- `df`: DataFrame con columnas `X`, `Y`, `distrito`

**Retorna**: DataFrame con columnas `distrito`, `cent_x`, `cent_y`

#### `build_adjacency_from_centroids(centroids: pd.DataFrame, k: int = 4) -> Tuple[np.ndarray, List[str]]`

Construye matriz de adyacencia basada en k-vecinos mÃ¡s cercanos.

**ParÃ¡metros**:
- `centroids`: DataFrame con centroides
- `k`: NÃºmero de vecinos a conectar

**Retorna**: Tupla `(A_norm, district_names)` donde `A_norm` es matriz normalizada y `district_names` es lista ordenada de distritos

#### `aggregate_yearly_counts(df: pd.DataFrame, district_order: List[str]) -> pd.DataFrame`

Agrega conteos de delitos por aÃ±o y distrito.

**ParÃ¡metros**:
- `df`: DataFrame con datos de incidentes
- `district_order`: Orden de distritos para columnas

**Retorna**: DataFrame pivot con aÃ±os como Ã­ndice y distritos como columnas

### Clases del Modelo

#### `IntegratedModel`

Modelo principal que integra todos los componentes.

**ParÃ¡metros del constructor**:
- `n_nodes`: NÃºmero de distritos (nodos)
- `seq_len`: Longitud de ventana temporal
- `in_ch`: DimensiÃ³n de entrada (1 para conteos)
- `hidden`: DimensiÃ³n oculta
- `A_norm`: Matriz de adyacencia normalizada

**MÃ©todo forward**:
- `forward(seq: torch.Tensor) -> torch.Tensor`
  - Entrada: `(B, S, N)` donde B=batch, S=seq_len, N=n_nodes
  - Salida: `(B, N)` predicciones por distrito

### Uso ProgramÃ¡tico

Ejemplo de uso del modelo entrenado:

```python
import torch
from main_version_preliminar import IntegratedModel, CFG

# Cargar checkpoint
checkpoint = torch.load("ig_outputs/integrated_model.pt", map_location="cpu", weights_only=False)

# Extraer componentes
cfg_dict = checkpoint['cfg']
district_names = checkpoint['district_names']
A_norm = torch.tensor(checkpoint['A_norm'], dtype=torch.float32)
scaler_mean = checkpoint['scaler_mean']
scaler_scale = checkpoint['scaler_scale']

# Reconstruir modelo
model = IntegratedModel(
    n_nodes=len(district_names),
    seq_len=cfg_dict['seq_len'],
    in_ch=1,
    hidden=cfg_dict['hidden_dim'],
    A_norm=A_norm
)
model.load_state_dict(checkpoint['model'])
model.eval()

# Preparar datos (ejemplo: Ãºltimos 3 aÃ±os)
# input_window debe ser array de shape (seq_len, n_districts)
input_scaled = (input_window - scaler_mean) / scaler_scale
tensor_in = torch.tensor(input_scaled, dtype=torch.float32).unsqueeze(0)  # Agregar dimensiÃ³n batch

# Predecir
with torch.no_grad():
    pred_scaled = model(tensor_in).numpy()[0]

# Desnormalizar
pred_raw = (pred_scaled * scaler_scale) + scaler_mean
pred_raw = np.maximum(pred_raw, 0)  # Asegurar no negativos

# Resultado: pred_raw es array de shape (n_districts,)
```

---

## Deployment

### Opciones de Deployment

El sistema puede desplegarse en diferentes plataformas segÃºn los requisitos:

#### 1. Streamlit Cloud (Recomendado para MVP)

**Ventajas**:
- Deployment gratuito y sencillo
- IntegraciÃ³n directa con GitHub
- ActualizaciÃ³n automÃ¡tica con cada push

**Pasos**:
1. Sube el repositorio a GitHub
2. Ve a [share.streamlit.io](https://share.streamlit.io)
3. Conecta el repositorio
4. Configura el comando: `streamlit run app.py`
5. Especifica el archivo principal: `app.py`

**Limitaciones**:
- Requiere que el modelo entrenado estÃ© incluido en el repositorio (considera usar Git LFS para archivos grandes)
- Recursos limitados (CPU, memoria)

#### 2. Heroku

**Ventajas**:
- Control sobre recursos
- ConfiguraciÃ³n flexible

**Requisitos**:
- `Procfile`: `web: streamlit run app.py --server.port=$PORT --server.address=0.0.0.0`
- `runtime.txt`: Especifica versiÃ³n de Python
- Variables de entorno para configuraciÃ³n

#### 3. Docker + Servidor Cloud

**Ventajas**:
- MÃ¡ximo control y personalizaciÃ³n
- Escalabilidad horizontal posible

**Ejemplo de Dockerfile**:

```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

**Build y ejecuciÃ³n**:

```bash
docker build -t crime-prediction-app .
docker run -p 8501:8501 crime-prediction-app
```

#### 4. Servicios Cloud Empresariales

Para producciÃ³n a gran escala, considera:
- **AWS**: EC2 + ECS/EKS, S3 para almacenamiento de modelos
- **Google Cloud**: Cloud Run, Vertex AI
- **Azure**: App Service, Container Instances

### URL de Deployment

**AplicaciÃ³n Web Desplegada:**

ğŸŒ **URL de ProducciÃ³n**: [https://bladimiralfer-proyecto-cdd-app-ii1kxc.streamlit.app/](https://bladimiralfer-proyecto-cdd-app-ii1kxc.streamlit.app/)

**Plataforma**: Streamlit Cloud

**Estado**: âœ… Activa y funcionando

La aplicaciÃ³n estÃ¡ desplegada en Streamlit Cloud y es accesible pÃºblicamente. Incluye todas las funcionalidades descritas en la secciÃ³n [AplicaciÃ³n Web (Streamlit)](#aplicaciÃ³n-web-streamlit), incluyendo:

- VisualizaciÃ³n de predicciones en mapa 3D interactivo
- KPIs tÃ¡cticos en tiempo real
- Comparativas histÃ³ricas
- ExportaciÃ³n de datos
- Filtros avanzados por distrito y rango de incidentes

### Consideraciones para ProducciÃ³n

#### Seguridad

- **AutenticaciÃ³n**: Considera agregar autenticaciÃ³n para acceso restringido
- **ValidaciÃ³n de entrada**: Valida todos los inputs del usuario
- **Rate limiting**: Limita nÃºmero de requests por IP

#### Rendimiento

- **CachÃ© de modelo**: El modelo se carga en memoria al iniciar la app
- **OptimizaciÃ³n de queries**: Los datos histÃ³ricos se cargan una vez y se cachean
- **CDN**: Para servir assets estÃ¡ticos (si aplica)

#### Monitoreo

- **Logging**: Configura logging para errores y uso
- **MÃ©tricas**: Monitorea tiempo de respuesta, uso de memoria
- **Alertas**: Configura alertas para errores crÃ­ticos

#### ActualizaciÃ³n del Modelo

- **Versionado**: MantÃ©n versiones del modelo con timestamps
- **A/B Testing**: Prueba nuevos modelos en producciÃ³n con trÃ¡fico parcial
- **Rollback**: Plan de reversiÃ³n si el nuevo modelo falla

---

## MÃ©tricas y EvaluaciÃ³n

### MÃ©tricas Principales

El sistema utiliza las siguientes mÃ©tricas para evaluar el rendimiento:

#### 1. MAE (Mean Absolute Error)

**DefiniciÃ³n**: Error absoluto medio entre predicciones y valores reales.

**FÃ³rmula**: 
\[
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
\]

**InterpretaciÃ³n**: Representa el error promedio en las mismas unidades que la variable objetivo (nÃºmero de delitos). Un MAE de 200 significa que, en promedio, las predicciones se desvÃ­an 200 delitos del valor real.

**Uso**: MÃ©trica principal para evaluar precisiÃ³n absoluta. MÃ¡s robusta a outliers que RMSE.

#### 2. RMSE (Root Mean Squared Error)

**DefiniciÃ³n**: RaÃ­z del error cuadrÃ¡tico medio.

**FÃ³rmula**:
\[
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
\]

**InterpretaciÃ³n**: Penaliza mÃ¡s los errores grandes. Siempre mayor o igual que MAE. Un RMSE de 300 indica que los errores grandes tienen mayor peso en la evaluaciÃ³n.

**Uso**: Ãštil para identificar modelos con errores extremos. Usado como mÃ©trica de early stopping.

#### 3. MAPE (Mean Absolute Percentage Error)

**DefiniciÃ³n**: Error porcentual absoluto medio.

**FÃ³rmula**:
\[
MAPE = \frac{100}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right|
\]

**InterpretaciÃ³n**: Expresa el error como porcentaje del valor real. Un MAPE del 40% significa que, en promedio, las predicciones se desvÃ­an un 40% del valor real.

**Uso**: Ãštil para comparar rendimiento entre distritos con diferentes escalas de delitos. Solo calculado para valores no-cero.

**LimitaciÃ³n**: Puede ser problemÃ¡tico cuando los valores reales son cercanos a cero (divisiÃ³n por valores pequeÃ±os).

### InterpretaciÃ³n de Resultados

#### Rendimiento Esperado

Para un modelo bien entrenado en datos de delitos urbanos:

- **MAE**: 150-300 delitos (depende del rango de valores)
- **RMSE**: 200-400 delitos
- **MAPE**: 30-50% (aceptable debido a variabilidad inherente de delitos)

#### ComparaciÃ³n entre Modelos

Al comparar el modelo integrado vs baseline:

| MÃ©trica | Modelo Baseline | Modelo Integrado | Mejora |
|---------|----------------|------------------|--------|
| MAE     | [valor]        | [valor]          | [%]    |
| RMSE    | [valor]        | [valor]          | [%]    |
| MAPE    | [valor]        | [valor]          | [%]    |

**Criterios de evaluaciÃ³n**:
- **Mejora significativa**: ReducciÃ³n â‰¥ 5% en MAE o RMSE
- **Mejora marginal**: ReducciÃ³n < 5% pero > 0%
- **Sin mejora o regresiÃ³n**: Aumento en mÃ©tricas (requiere investigaciÃ³n)

### ValidaciÃ³n Cruzada Temporal

Para evaluaciÃ³n mÃ¡s robusta, considera validaciÃ³n cruzada temporal:

1. **Walk-forward validation**: Entrena en [2016-2019], valida en 2020; luego entrena en [2016-2020], valida en 2021, etc.
2. **Expanding window**: Similar pero expandiendo la ventana de entrenamiento en cada iteraciÃ³n

**ImplementaciÃ³n futura**: Script de validaciÃ³n cruzada temporal (ver `grid_search.py` como referencia).

### AnÃ¡lisis de Errores

Para entender mejor el comportamiento del modelo:

1. **Errores por distrito**: Identifica distritos con mayor error (puede indicar necesidad de mÃ¡s datos o features adicionales)
2. **Errores por rango de valores**: EvalÃºa si el modelo funciona mejor en distritos con muchos delitos vs pocos
3. **Errores temporales**: Verifica si hay sesgo en predicciones de aÃ±os especÃ­ficos

**Ejemplo de anÃ¡lisis**:

```python
# DespuÃ©s de entrenamiento
errors = abs(predictions - actuals)
high_error_districts = errors.nlargest(10).index
print(f"Distritos con mayor error: {high_error_districts}")
```

---

## Estructura del Proyecto

```
Proyecto_CDD/
â”‚
â”œâ”€â”€ data/                          # Datos de entrada
â”‚   â”œâ”€â”€ final2016.csv              # Datos aÃ±o 2016
â”‚   â”œâ”€â”€ final2017.csv              # Datos aÃ±o 2017
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ final2023.csv              # Datos aÃ±o 2023
â”‚
â”œâ”€â”€ ig_outputs/                    # Salidas del modelo integrado
â”‚   â”œâ”€â”€ integrated_model.pt        # Modelo entrenado (checkpoint)
â”‚   â””â”€â”€ report.json                # Reporte de mÃ©tricas
â”‚
â”œâ”€â”€ outputs/                       # Salidas del modelo baseline
â”‚   â”œâ”€â”€ metrics.json               # MÃ©tricas del modelo baseline
â”‚   â”œâ”€â”€ feature_importance.csv     # Importancia de features
â”‚   â”œâ”€â”€ predictions_2023.csv       # Predicciones aÃ±o 2023
â”‚   â””â”€â”€ predictions_2024.csv       # Predicciones aÃ±o 2024
â”‚
â”œâ”€â”€ app.py                         # AplicaciÃ³n Streamlit (interfaz web)
â”‚
â”œâ”€â”€ main.py                        # Pipeline modelo baseline (RF/XGBoost)
â”‚
â”œâ”€â”€ main_version_preliminar.py     # Pipeline modelo integrado (GCN+LSTM+Attention)
â”‚
â”œâ”€â”€ grid_search.py                 # BÃºsqueda de hiperparÃ¡metros
â”‚
â”œâ”€â”€ modelando_MVP.ipynb            # Notebook de experimentaciÃ³n
â”‚
â”œâ”€â”€ hex_pordistrito.csv            # Mapeo de hexÃ¡gonos H3 a distritos (opcional)
â”‚
â”œâ”€â”€ requirements.txt               # Dependencias Python
â”‚
â”œâ”€â”€ README.md                      # Este archivo
â”‚
â”œâ”€â”€ COMMITMENTS.md                 # Plan de trabajo y compromisos
â”‚
â””â”€â”€ PLAN.md                        # Plan estratÃ©gico y decisiones de diseÃ±o
```

### DescripciÃ³n de Archivos Clave

#### `app.py`
AplicaciÃ³n web interactiva con Streamlit. Requiere modelo entrenado en `ig_outputs/integrated_model.pt`.

#### `main_version_preliminar.py`
Pipeline completo del modelo integrado. Contiene:
- Carga y preprocesamiento de datos
- ConstrucciÃ³n del grafo
- DefiniciÃ³n del modelo
- Entrenamiento y evaluaciÃ³n
- Guardado de artefactos

#### `main.py`
Pipeline del modelo baseline. Utiliza enfoque basado en Ã¡rboles con features temporales y espaciales.

#### `grid_search.py`
Script para optimizaciÃ³n de hiperparÃ¡metros mediante bÃºsqueda en grid o random search.

#### `requirements.txt`
Lista de todas las dependencias Python necesarias para el proyecto.

---

## Referencias

### Paper Principal

**Hou, X., et al.** (2022). "An Integrated Graph Model for Spatialâ€“Temporal Urban Crime Prediction Based on Attention Mechanism". *[Revista/Conferencia]*.

Este paper proporciona la base teÃ³rica para la arquitectura del modelo integrado, especÃ­ficamente:
- Uso de GCN para relaciones espaciales
- LSTM para dependencias temporales
- Mecanismo de atenciÃ³n para ponderaciÃ³n temporal

### Referencias Adicionales

1. **Cesario, E., et al.** (2024). "Multi-density crime predictor: an approach to forecast criminal high-risk areas in urban environments". *[Revista]*.

   Propone enfoque adaptativo para capturar patrones espaciales heterogÃ©neos. Considerado para futuras mejoras.

2. **Kipf, T. N., & Welling, M.** (2017). "Semi-Supervised Classification with Graph Convolutional Networks". *ICLR*.

   Trabajo fundamental sobre GCN utilizado como base para la capa de convoluciÃ³n de grafos.

3. **Hochreiter, S., & Schmidhuber, J.** (1997). "Long Short-Term Memory". *Neural Computation*.

   Arquitectura LSTM original, base para el componente temporal del modelo.

4. **Vaswani, A., et al.** (2017). "Attention Is All You Need". *NeurIPS*.

   IntroducciÃ³n del mecanismo de atenciÃ³n, adaptado para atenciÃ³n temporal en este proyecto.

### Datos y Recursos

- **Datos de delitos**: Fuente gubernamental (especificar si es pÃºblico o privado)
- **Coordenadas geogrÃ¡ficas**: Sistema de coordenadas utilizado (ej: WGS84, UTM)
- **LÃ­mites administrativos**: Si se utilizan en futuras versiones (fuente: [especificar])

### Herramientas y LibrerÃ­as

- **PyTorch**: Framework de deep learning ([pytorch.org](https://pytorch.org/))
- **Streamlit**: Framework para aplicaciones web en Python ([streamlit.io](https://streamlit.io/))
- **PyDeck**: VisualizaciÃ³n de mapas 3D ([pydeck.gl](https://pydeck.gl/))
- **scikit-learn**: Herramientas de ML tradicional ([scikit-learn.org](https://scikit-learn.org/))

---

## SoluciÃ³n de Problemas

### Errores Comunes y Soluciones

#### Error: "No se encontraron CSV con el patrÃ³n"

**Causa**: Los archivos CSV no estÃ¡n en la ubicaciÃ³n esperada o no siguen el patrÃ³n de nombres.

**SoluciÃ³n**:
```bash
# Verificar que los archivos existen
ls data/final*.csv

# Verificar el patrÃ³n en el cÃ³digo
# En main_version_preliminar.py, verifica:
cfg.data_glob = "./data/final*.csv"  # Ajusta la ruta si es necesario
```

#### Error: "La serie tiene solo X pasos"

**Causa**: No hay suficientes aÃ±os de datos para crear ventanas temporales de longitud `seq_len`.

**SoluciÃ³n**:
```python
# Reduce seq_len en la configuraciÃ³n
cfg.seq_len = 2  # En lugar de 3

# O verifica que tienes suficientes aÃ±os
# Necesitas al menos seq_len + 1 aÃ±os (ej: seq_len=3 requiere mÃ­nimo 4 aÃ±os)
```

#### Error: "Falta columna requerida"

**Causa**: Los CSV no tienen todas las columnas necesarias.

**SoluciÃ³n**:
Verifica que cada CSV tenga estas columnas:
- `anio` (numÃ©rico)
- `X` (numÃ©rico, longitud)
- `Y` (numÃ©rico, latitud)
- `distrito` (texto)

Usa pandas para inspeccionar:
```python
import pandas as pd
df = pd.read_csv("data/final2016.csv")
print(df.columns.tolist())
```

#### Error: "CUDA out of memory"

**Causa**: El modelo es demasiado grande para la GPU disponible, o el batch_size es muy grande.

**SoluciÃ³n**:
```python
# OpciÃ³n 1: Reducir batch_size
cfg.batch_size = 32  # O 16, o 8

# OpciÃ³n 2: Reducir hidden_dim
cfg.hidden_dim = 32  # En lugar de 64

# OpciÃ³n 3: Usar CPU
cfg.device = "cpu"
```

#### Error: "Modelo no converge" (pÃ©rdida no disminuye o NaN)

**Causa**: Learning rate muy alto, datos no normalizados correctamente, o gradientes explotando.

**SoluciÃ³n**:
```python
# Reducir learning rate
cfg.lr = 5e-4  # O 1e-4

# Verificar normalizaciÃ³n de datos
# AsegÃºrate de que el scaler se ajusta solo con datos de entrenamiento

# Agregar gradient clipping (si no estÃ¡ ya)
# En el loop de entrenamiento:
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

#### Error: Streamlit no carga el modelo

**Causa**: El archivo `ig_outputs/integrated_model.pt` no existe o estÃ¡ corrupto.

**SoluciÃ³n**:
```bash
# Verificar que el modelo existe
ls -lh ig_outputs/integrated_model.pt

# Si no existe, entrena primero:
python main_version_preliminar.py

# Verificar que el checkpoint es vÃ¡lido
python -c "import torch; torch.load('ig_outputs/integrated_model.pt', map_location='cpu')"
```

#### Error: "Distritos no coinciden" en Streamlit

**Causa**: Los nombres de distritos en los CSV no coinciden exactamente con los del modelo entrenado.

**SoluciÃ³n**:
- Verifica normalizaciÃ³n de nombres (mayÃºsculas, espacios)
- El pipeline normaliza nombres a mayÃºsculas y elimina espacios
- AsegÃºrate de usar los mismos datos de entrenamiento y predicciÃ³n

### OptimizaciÃ³n de Rendimiento

#### Entrenamiento muy lento

**Soluciones**:
1. Usar GPU si estÃ¡ disponible
2. Reducir `batch_size` solo si hay problemas de memoria (batch mÃ¡s grande suele ser mÃ¡s rÃ¡pido)
3. Reducir `hidden_dim` o `seq_len`
4. Reducir nÃºmero de Ã©pocas (usar early stopping)

#### AplicaciÃ³n Streamlit lenta

**Soluciones**:
1. Verificar que `@st.cache_resource` y `@st.cache_data` estÃ¡n siendo usados
2. Reducir cantidad de distritos mostrados en el mapa
3. Simplificar visualizaciones (menos datos en grÃ¡ficos)
4. Usar datos muestreados para visualizaciÃ³n rÃ¡pida

### DepuraciÃ³n

#### Logging detallado

Agrega logging para entender el flujo:

```python
import logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# En funciones clave:
logger.debug(f"Cargando {len(files)} archivos CSV")
logger.info(f"Entrenando con {len(train_dataset)} ejemplos")
```

#### Verificar dimensiones de tensores

Agrega prints temporales para verificar shapes:

```python
# En el forward del modelo
print(f"Input shape: {x.shape}")
x = self.resblock(x)
print(f"After resblock: {x.shape}")
# ... etc
```

#### Validar datos de entrada

```python
# Verificar que no hay NaN o infinitos
assert not np.isnan(input_window).any(), "NaN en datos de entrada"
assert not np.isinf(input_window).any(), "Inf en datos de entrada"
```





